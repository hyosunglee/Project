import requests
from bs4 import BeautifulSoup
from utils.summarizer import summarize_text

ARXIV_QUERY = "machine learning"
MAX_RESULTS = 3

def fetch_arxiv_papers(query, max_results=5):
    url = f'http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results={max_results}'
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'xml')
    entries = soup.find_all('entry')
    papers = []

    for entry in entries:
        title = entry.title.text.strip().replace('\n', ' ')
        summary = entry.summary.text.strip().replace('\n', ' ')
        papers.append((title, summary))
    
    return papers

def main():
    papers = fetch_arxiv_papers(ARXIV_QUERY, MAX_RESULTS)
    for i, (title, abstract) in enumerate(papers):
        print(f"\n--- Paper {i+1} ---")
        print("Title:", title)
        print("\nSummary:\n", abstract)
        print("\n--- GPT Summary ---")
        print(summarize_text(abstract))

if __name__ == "__main__":
    main()