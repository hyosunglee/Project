아주 잘 됐다 😎
경로 OK, 그리고 이제 진짜 모델 학습하고 예측까지 자동화한다.

⸻

🔍 Step 1: result 값 안에 정확히 뭐가 들어있는지 확인

✅ 확인 방법

logs/experiment_logs.json 파일에서 "result" 항목만 싹 모아서 확인하면 돼.
코드로 하면 아주 간단해:

import json

with open("logs/experiment_logs.json", "r") as f:
    logs = json.load(f)

results = [log.get("result", "") for log in logs]

for i, r in enumerate(results):
    print(f"{i+1}. {r}")

이걸로 아래 같은 출력이 나올 거야:

1. Experiment with accuracy 0.81
2. Reward: 0.9
3. Success rate = 78%
4. Experiment with accuracy 0.73


⸻

🧠 이렇게 처리하면 좋음
	1.	accuracy 있는 건 → accuracy 예측용 학습
	2.	reward, success, etc. 있는 건 → 추후 확장 (멀티타깃 or 조건별)

우선은 accuracy만 추출해서 선형회귀 모델 만들어보자.

⸻

✅ 최종 모델 학습 코드

📁 utils/model_trainer.py 파일에 아래 전체 코드 복붙해도 돼:

import json
import re
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error


def extract_accuracy(result_str):
    match = re.search(r"accuracy\s*([0-9.]+)", result_str, re.IGNORECASE)
    if match:
        return float(match.group(1))
    return None


def train_model_from_logs():
    with open("logs/experiment_logs.json", "r") as f:
        logs = json.load(f)

    X_texts = []
    y = []

    for log in logs:
        acc = extract_accuracy(log.get("result", ""))
        if acc is None:
            continue

        input_text = f"{log.get('summary', '')} {log.get('idea', '')} {log.get('code', '')}"
        X_texts.append(input_text)
        y.append(acc)

    if len(X_texts) < 5:
        print("❗ 학습 데이터가 너무 적습니다. 최소 5개 이상 필요합니다.")
        return

    vectorizer = TfidfVectorizer(max_features=1000)
    X = vectorizer.fit_transform(X_texts)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = LinearRegression()
    model.fit(X_train, y_train)

    pred = model.predict(X_test)
    mse = mean_squared_error(y_test, pred)
    print(f"✅ 모델 학습 완료. 테스트 MSE: {mse:.4f}")


⸻

🚀 학습 실행
	1.	/loop 몇 번 호출해서 데이터 쌓고
	2.	아래로 학습 트리거:

curl -X POST http://localhost:3000/train

	3.	터미널에 결과 확인:

✅ 모델 학습 완료. 테스트 MSE: 0.0148


⸻

🔮 다음 스텝
	•	예측 모델 저장 (joblib) → 실험 전에 미리 “좋을 것 같은 논문” 예측
	•	reward, success rate, loss 등도 예측 (멀티타깃)
	•	시각화: 어떤 단어가 높은 성능에 영향을 미쳤는지 (SHAP, permutation importance)
	•	성능 높은 논문 아이디어만 자동 선택 실험 🧠⚙️

⸻

이제 모델은 살아있다.
실험 전 예측도 가능해지고, 연구 자동화의 핵심부로 들어왔어.

📢 지금부터는 진짜 “성능을 예측해 먼저 판단하고, 실험은 나중”인 시대야.
원하면 바로 예측 API까지 붙여줄게. 계속 가볼까? 😎