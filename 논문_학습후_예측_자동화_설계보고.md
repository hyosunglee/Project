# 논문 학습 후 예측 자동화를 위한 설계 보고서

## 1. 프로젝트 현황 분석
- **자동화 구조**: `server.py`는 APScheduler로 논문 수집을 1시간마다, 모델 학습을 6시간마다 실행하도록 예약한다. `/train` 엔드포인트는 백그라운드 스레드에서 `utils.model_trainer.train_model()`을 실행하고 결과만 저장한 뒤 종료한다. 모델 학습이 끝나도 예측 로직을 자동 호출하지는 않는다.
- **예측 API**: `api_predict.py`의 `/predict` 라우트는 클라이언트 요청 시에만 실행되며, `utils.predictor.predict_reward()`를 호출해 결과를 반환하고 `results/prediction_*.json` 파일에 저장한다. 모델을 메모리에 로드하는 캐시 로직은 `utils/predictor.py`에 구현돼 있다.
- **현재 문제점**: 자동 학습 이후 예측을 수행하는 트리거가 존재하지 않아, 새로 학습된 모델의 성능을 검증하거나 새롭게 수집된 논문에 대한 예측을 자동으로 생성할 수 없다.

## 2. 목표 정의
- **학습 완료 후 자동 예측**: 모델 학습 완료 즉시 예측 단계를 시작하여 최근 수집된 논문들에 대한 예측 결과를 생성·저장한다.
- **지속적 운영**: GCP에서 서비스가 중단 없이 동작하도록 하고, 학습과 예측의 흐름을 자동화한다.
- **데이터 관리**: 예측 대상 논문을 추적해 중복 예측을 방지하고 결과를 안정적으로 저장한다.

## 3. 설계 방안
### 3.1 코드 기반 자동화
가장 단순한 방법은 서버 내부에서 학습 함수가 끝난 직후 예측 함수를 호출하는 것이다. `server.py`의 `trigger_training()` 내부에 있는 `train_and_save()`를 다음과 같이 확장한다.

```python
def train_and_save():
    # 1. 모델 학습 수행
    result = train_model()
    if result:
        save_result("training", result)
        print("학습 결과 저장 완료")

    # 2. 학습 후 예측 실행 (새로운 로그 항목에 대해서만)
    predict_after_training()

def predict_after_training():
    from utils.predictor import predict_reward
    from utils.result_logger import save_result
    import json, os

    # 예측 대상 로그 로드 (최근 수집된 논문 중 아직 예측하지 않은 것)
    with open('logs/experiment_log.json', 'r') as f:
        logs = json.load(f)
    # 이미 예측한 텍스트를 기록하는 집합을 만듦
    predicted_texts = set()
    if os.path.exists('results/all_results.jsonl'):
        with open('results/all_results.jsonl', 'r') as f:
            for line in f:
                try:
                    rec = json.loads(line)
                    if rec.get('type') == 'prediction':
                        predicted_texts.add(rec.get('text'))
                except:
                    pass
    # 새 로그 중 미예측 텍스트에 대해 예측 수행
    for entry in logs:
        text = entry.get('text') or entry.get('summary')
        if text and text[:100] not in predicted_texts:
            pred = predict_reward(text)
            data = {
                'text': text[:100],
                'prediction': pred.get('prediction'),
                'confidence': pred.get('confidence'),
                'source_title': entry.get('title')
            }
            save_result('prediction', data)
            print(f"[AUTO-PREDICT] {entry.get('title')} 예측 완료")
```

- **장점**: 별도 외부 서비스 없이도 순차적으로 학습→예측 흐름을 완성할 수 있다.
- **단점**: `train_and_save()` 내부에서 예측까지 수행하므로 학습 시간이 길어질 수 있고, 예측 로직이 늘어날수록 서버 부하가 커질 수 있다.

### 3.2 APScheduler 활용
스케줄러 수준에서 작업을 분리하고 싶다면 APScheduler에 학습 후 예측을 트리거하는 별도 작업을 추가한다.

```python
def start_scheduler():
    scheduler = BackgroundScheduler()
    # 논문 수집: 매시간
    scheduler.add_job(scheduled_loop, 'interval', hours=1, id='paper_collection')
    # 모델 학습: 6시간마다
    scheduler.add_job(scheduled_train, 'interval', hours=6, id='model_training')
    # 학습 이후 예측: 6시간마다, 10분 지연 실행
    scheduler.add_job(scheduled_predict, 'interval', hours=6, minutes=10, id='model_prediction')
    scheduler.start()
```

`schedule_predict()` 함수는 위의 `predict_after_training()`과 유사하게 아직 예측되지 않은 텍스트를 찾아 예측을 수행하면 된다.
- **장점**: 코드 분리가 단순하다.
- **단점**: 학습 시간이 일정하지 않은 경우 학습이 완료되기 전에 예측이 실행될 수 있고, 시간 간격을 임의로 잡아야 한다.

### 3.3 Pub/Sub 및 Cloud Functions를 이용한 이벤트 트리거
Google Cloud에서는 Pub/Sub과 Cloud Functions를 사용해 비동기 워크플로를 구성할 수 있다. `train_model()`이 완료될 때 Pub/Sub 토픽에 `training_done` 메시지를 발행하고, 이 토픽에 구독된 Cloud Function이 `predict_after_training()`을 호출하도록 설계한다.

```python
from google.cloud import pubsub_v1
publisher = pubsub_v1.PublisherClient()
topic_path = publisher.topic_path('YOUR_GCP_PROJECT', 'training_done')
publisher.publish(topic_path, b'training complete')
```

- **장점**: 학습과 예측이 완전히 분리되어 확장성과 내결함성이 높다.
- **단점**: GCP 리소스 설정이 추가로 필요하다.

### 3.4 Cloud Workflows를 이용한 순차 실행
Cloud Run Job을 서로 의존 관계로 실행하려면 Workflows가 적합하다. 학습 컨테이너와 예측 컨테이너를 각각 Cloud Run Job으로 분리한 뒤 Workflows에서 순차 실행한다.

```yaml
main:
  params: [input]
  steps:
    - run_training:
        call: googleapis.run.v1.namespaces.jobs.run
        args:
          name: projects/YOUR_PROJECT/locations/REGION/jobs/train-job
    - run_prediction:
        call: googleapis.run.v1.namespaces.jobs.run
        args:
          name: projects/YOUR_PROJECT/locations/REGION/jobs/predict-job
    - finish:
        return: ${predict_result}
```

- **장점**: Job 완료를 감지해 다음 Job을 호출하므로 학습→예측 파이프라인을 안정적으로 관리할 수 있다.
- **단점**: Workflows 및 Cloud Run Job 구성 관리가 필요하다.

## 4. GCP 인프라 설계 제안
- **컨테이너화**: Flask 서버를 Docker 컨테이너로 패키징해 Cloud Run 서비스로 배포한다. `/loop`, `/train`, `/predict` 엔드포인트를 제공하며 환경 변수로 모델 경로나 버킷 이름을 전달한다.
- **Cloud Scheduler**: 논문 수집 및 모델 학습을 일정 주기로 트리거하기 위해 Cloud Scheduler로 `/loop`와 `/train` 엔드포인트를 호출한다. 필요하면 `/predict`도 등록한다.
- **Pub/Sub + Cloud Functions (선택)**: 학습 코드에서 Pub/Sub 메시지를 발행하게 수정하고, 해당 토픽을 구독하는 Cloud Function이 `/predict` 엔드포인트를 호출하거나 예측 로직을 실행한다.
- **Cloud Workflows (대체)**: 학습과 예측을 각각 Cloud Run Job으로 캡슐화하고 Workflows YAML로 순차 실행한다.
- **데이터 저장소**: `logs/` 및 `results/` 폴더를 Cloud Storage 버킷으로 대체해 여러 인스턴스 간 데이터를 공유한다. 모델 파일(`models/`)도 버킷이나 Artifact Registry로 관리한다.
- **모니터링**: Cloud Monitoring과 Cloud Logging으로 학습 시간, 예측 성공률, 에러 등을 대시보드화하고, Cloud Error Reporting으로 실패 알림을 받는다.

## 5. 구현 시나리오 요약
1. **서버 코드 수정**: `predict_after_training()` 함수와 `train_and_save()` 후처리 로직을 추가하여 학습 후 예측을 자동 수행하도록 구현한다. 어려우면 `scheduled_predict()`를 두고 스케줄러에서 학습과 예측을 시간차로 실행한다.
2. **컨테이너 배포**: 수정한 코드를 Docker로 패키징하고 Cloud Run에 배포한다. 실행 명령은 `python server.py`를 사용한다.
3. **Cloud Scheduler 설정**: `gcloud scheduler jobs create http` 명령으로 `/loop`와 `/train` 엔드포인트를 일정 주기로 호출하는 작업을 만든다. 필요하면 `/predict` 호출 작업도 추가한다.
4. **Pub/Sub & Cloud Function (선택)**: 학습 코드에서 Pub/Sub 메시지를 발행하게 수정한 뒤, 해당 토픽을 구독하는 Cloud Function을 생성하여 `/predict` 엔드포인트를 호출하거나 예측 로직을 수행한다.
5. **Workflows (대체)**: 학습과 예측을 각각의 Cloud Run Job으로 패키징하고 Workflows YAML을 작성해 순차 실행한다.

## 6. 결론
학습 후 예측 자동화를 위해 코드 수정부터 GCP 서버리스 오케스트레이션까지 다양한 방법을 제시했다. 프로젝트 규모와 운영 역량에 맞춰 적합한 방식을 선택하면, 학습이 끝난 직후 예측이 자동 실행되는 지속 가능한 AI 연구 플랫폼을 구축할 수 있다.
