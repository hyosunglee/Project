{"timestamp": "2025-11-17T06:48:12.902001", "type": "training", "data": {"model": "models/reward_cls_20251117_064812.pkl", "timestamp": "20251117_064812", "data_count": 112, "train_size": 89, "test_size": 23, "accuracy": 0.6087, "f1_score": 0.7273}}
{"timestamp": "2025-11-17T06:48:16.616574", "type": "collection", "data": {"collected_count": 0, "papers": []}}
{"timestamp": "2025-11-17T07:17:26.781895", "type": "training", "data": {"model": "models/reward_cls_20251117_071726.pkl", "timestamp": "20251117_071726", "data_count": 181, "train_size": 144, "test_size": 37, "accuracy": 0.5676, "f1_score": 0.7143}}
{"timestamp": "2025-11-17T07:17:30.203620", "type": "collection", "data": {"collected_count": 0, "papers": []}}
{"timestamp": "2025-11-17T07:45:55.773719", "type": "training", "data": {"model": "models/reward_cls_20251117_074555.pkl", "timestamp": "20251117_074555", "data_count": 259, "train_size": 207, "test_size": 52, "accuracy": 0.6346, "f1_score": 0.7246}}
{"timestamp": "2025-11-17T07:46:00.137656", "type": "collection", "data": {"collected_count": 25, "papers": [{"title": "Drone Swarm Energy Management", "summary": "This note presents an analytical framework for decision-making in drone swarm systems operating unde"}, {"title": "Multistability of Self-Attention Dynamics in Transformers", "summary": "In machine learning, a self-attention dynamics is a continuous-time multiagent-like model of the att"}, {"title": "Aligning Machiavellian Agents: Behavior Steering via Test-Time Policy Shaping", "summary": "The deployment of decision-making AI agents presents a critical challenge in maintaining alignment w"}, {"title": "HetDAPAC: Leveraging Attribute Heterogeneity in Distributed Attribute-Based Private Access Control", "summary": "Verifying user attributes to provide fine-grained access control to databases is fundamental to attr"}, {"title": "Incremental Data-Driven Policy Synthesis via Game Abstractions", "summary": "We address the synthesis of control policies for unknown discrete-time stochastic dynamical systems "}, {"title": "Generalizing Fair Clustering to Multiple Groups: Algorithms and Applications", "summary": "Clustering is a fundamental task in machine learning and data analysis, but it frequently fails to p"}, {"title": "Terrain Costmap Generation via Scaled Preference Conditioning", "summary": "Successful autonomous robot navigation in off-road domains requires the ability to generate high-qua"}, {"title": "CVChess: A Deep Learning Framework for Converting Chessboard Images to Forsyth-Edwards Notation", "summary": "Chess has experienced a large increase in viewership since the pandemic, driven largely by the acces"}, {"title": "Scalable Policy Evaluation with Video World Models", "summary": "Training generalist policies for robotic manipulation has shown great promise, as they enable langua"}, {"title": "Experience-Guided Adaptation of Inference-Time Reasoning Strategies", "summary": "Enabling agentic AI systems to adapt their problem-solving approaches based on post-training interac"}, {"title": "W2S-AlignTree: Weak-to-Strong Inference-Time Alignment for Large Language Models via Monte Carlo Tree Search", "summary": "Large Language Models (LLMs) demonstrate impressive capabilities, yet their outputs often suffer fro"}, {"title": "Distributed Optimization of Pairwise Polynomial Graph Spectral Functions via Subgraph Optimization", "summary": "We study distributed optimization of finite-degree polynomial Laplacian spectral objectives under fi"}, {"title": "Collaborative Representation Learning for Alignment of Tactile, Language, and Vision Modalities", "summary": "Tactile sensing offers rich and complementary information to vision and language, enabling robots to"}, {"title": "OpenUS: A Fully Open-Source Foundation Model for Ultrasound Image Analysis via Self-Adaptive Masked Contrastive Learning", "summary": "Ultrasound (US) is one of the most widely used medical imaging modalities, thanks to its low cost, p"}, {"title": "FarSkip-Collective: Unhobbling Blocking Communication in Mixture of Experts Models", "summary": "Blocking communication presents a major hurdle in running MoEs efficiently in distributed settings. "}, {"title": "Honesty over Accuracy: Trustworthy Language Models through Reinforced Hesitation", "summary": "Modern language models fail a fundamental requirement of trustworthy intelligence: knowing when not "}, {"title": "Learning and Testing Convex Functions", "summary": "We consider the problems of \\emph{learning} and \\emph{testing} real-valued convex functions over Gau"}, {"title": "Photonic-integrated quantum sensor array for microscale magnetic localisation", "summary": "Nitrogen-vacancy centres (NVs) are promising solid-state nanoscale quantum sensors for applications "}, {"title": "Intrinsic Dimension Estimation for Radio Galaxy Zoo using Diffusion Models", "summary": "In this work, we estimate the intrinsic dimension (iD) of the Radio Galaxy Zoo (RGZ) dataset using a"}, {"title": "Power law attention biases for molecular transformers", "summary": "Transformers are the go-to architecture for most data modalities due to their scalability. While the"}, {"title": "Data-efficient U-Net for Segmentation of Carbide Microstructures in SEM Images of Steel Alloys", "summary": "Understanding reactor-pressure-vessel steel microstructure is crucial for predicting mechanical prop"}, {"title": "Risk-Aware Deep Reinforcement Learning for Dynamic Portfolio Optimization", "summary": "This paper presents a deep reinforcement learning (DRL) framework for dynamic portfolio optimization"}, {"title": "Inferring response times of perceptual decisions with Poisson variational autoencoders", "summary": "Many properties of perceptual decision making are well-modeled by deep neural networks. However, suc"}, {"title": "Context-aware Adaptive Visualizations for Critical Decision Making", "summary": "Effective decision-making often relies on timely insights from complex visual data. While Informatio"}, {"title": "Quantifying and Improving Adaptivity in Conformal Prediction through Input Transformations", "summary": "Conformal prediction constructs a set of labels instead of a single point prediction, while providin"}]}}
{"timestamp": "2025-11-17T07:46:03.439347", "type": "collection", "data": {"collected_count": 1, "papers": [{"title": "Stable Quantum Vortices in Lee-Huang-Yang Dipolar Superfluids", "summary": "The nucleation and dynamics of vortices in the quasi-two-dimensional rotating dipolar Bose-Einstein "}]}}
{"timestamp": "2025-11-17T08:47:14.310915", "type": "training", "data": {"model": "models/reward_cls_20251117_084714.pkl", "timestamp": "20251117_084714", "data_count": 430, "train_size": 344, "test_size": 86, "accuracy": 0.6279, "f1_score": 0.7333}}
{"timestamp": "2025-11-17T08:47:19.109781", "type": "collection", "data": {"collected_count": 0, "papers": []}}
{"timestamp": "2025-11-17T08:48:22.861461", "type": "training", "data": {"model": "models/reward_cls_20251117_084822.pkl", "timestamp": "20251117_084822", "data_count": 391, "train_size": 312, "test_size": 79, "accuracy": 0.6582, "f1_score": 0.7568}}
{"timestamp": "2025-11-17T08:51:07.559923", "type": "training", "data": {"model": "models/reward_cls_20251117_085107.pkl", "timestamp": "20251117_085107", "data_count": 33, "train_size": 26, "test_size": 7, "accuracy": 0.4286, "f1_score": 0.5}}
{"timestamp": "2025-11-17T09:52:00.468339", "type": "training", "data": {"model": "models/reward_cls_20251117_095200.pkl", "timestamp": "20251117_095200", "data_count": 33, "train_size": 26, "test_size": 7, "accuracy": 0.4286, "f1_score": 0.5}}
{"timestamp": "2025-11-17T09:52:04.625938", "type": "collection", "data": {"collected_count": 0, "papers": []}}
{"timestamp": "2025-11-17T10:12:06.669737", "type": "training", "data": {"model": "models/reward_cls_20251117_101206.pkl", "timestamp": "20251117_101206", "data_count": 62, "train_size": 49, "test_size": 13, "accuracy": 1.0, "f1_score": 1.0}}
{"timestamp": "2025-11-17T10:12:09.966447", "type": "collection", "data": {"collected_count": 0, "papers": []}}
{"timestamp": "2025-11-17T10:56:38.022557", "type": "training", "data": {"model": "models/reward_cls_20251117_105638.pkl", "timestamp": "20251117_105638", "data_count": 73, "train_size": 58, "test_size": 15, "accuracy": 1.0, "f1_score": 1.0}}
{"timestamp": "2025-11-17T10:56:42.183944", "type": "collection", "data": {"collected_count": 0, "papers": []}}
{"timestamp": "2025-11-17T12:07:54.770530", "type": "training", "data": {"model": "models/reward_cls_20251117_120754.pkl", "timestamp": "20251117_120754", "data_count": 73, "train_size": 58, "test_size": 15, "accuracy": 1.0, "f1_score": 1.0}}
{"timestamp": "2025-11-17T12:07:58.844372", "type": "collection", "data": {"collected_count": 0, "papers": []}}
{"timestamp": "2025-11-17T12:47:58.183472", "type": "training", "data": {"model": "models/reward_cls_20251117_124758.pkl", "timestamp": "20251117_124758", "data_count": 73, "train_size": 58, "test_size": 15, "accuracy": 1.0, "f1_score": 1.0}}
{"timestamp": "2025-11-17T12:48:02.382619", "type": "collection", "data": {"collected_count": 0, "papers": []}}
{"timestamp": "2025-11-17T13:06:37.815385", "type": "collection", "data": {"collected_count": 0, "papers": []}}
{"timestamp": "2025-11-17T13:07:53.316145", "type": "training", "data": {"model": "models/reward_cls_20251117_130753.pkl", "timestamp": "20251117_130753", "data_count": 73, "train_size": 58, "test_size": 15, "accuracy": 1.0, "f1_score": 1.0}}
{"timestamp": "2025-11-17T13:07:56.660842", "type": "collection", "data": {"collected_count": 0, "papers": []}}
{"timestamp": "2025-11-17T13:08:54.790277", "type": "collection", "data": {"collected_count": 0, "papers": []}}
{"timestamp": "2025-11-17T13:30:15.229363", "type": "training", "data": {"model": "models/reward_cls_20251117_133015.pkl", "timestamp": "20251117_133015", "data_count": 73, "train_size": 58, "test_size": 15, "accuracy": 1.0, "f1_score": 1.0}}
{"timestamp": "2025-11-17T13:30:20.292648", "type": "collection", "data": {"collected_count": 30, "papers": [{"title": "ARLBench: Flexible and Efficient Benchmarking for Hyperparameter Optimization in Reinforcement Learning", "summary": "Hyperparameters are a critical factor in reliably training well-performing reinforcement learning (R"}, {"title": "Causal-Paced Deep Reinforcement Learning", "summary": "Designing effective task sequences is crucial for curriculum reinforcement learning (CRL), where age"}, {"title": "Exploring Hierarchy-Aware Inverse Reinforcement Learning", "summary": "We introduce a new generative model for human planning under the Bayesian Inverse Reinforcement Lear"}, {"title": "A Tutorial on Meta-Reinforcement Learning", "summary": "While deep reinforcement learning (RL) has fueled multiple high-profile successes in machine learnin"}, {"title": "Anderson Acceleration for Reinforcement Learning", "summary": "Anderson acceleration is an old and simple method for accelerating the computation of a fixed point."}, {"title": "Stabilizing Extreme Q-learning by Maclaurin Expansion", "summary": "In offline reinforcement learning, in-sample learning methods have been widely used to prevent perfo"}, {"title": "MERL: Multi-Head Reinforcement Learning", "summary": "A common challenge in reinforcement learning is how to convert the agent's interactions with an envi"}, {"title": "Compression and Localization in Reinforcement Learning for ATARI Games", "summary": "Deep neural networks have become commonplace in the domain of reinforcement learning, but are often "}, {"title": "Accelerating Training in Pommerman with Imitation and Reinforcement Learning", "summary": "The Pommerman simulation was recently developed to mimic the classic Japanese game Bomberman, and fo"}, {"title": "Will it Blend? Composing Value Functions in Reinforcement Learning", "summary": "An important property for lifelong-learning agents is the ability to combine existing skills to solv"}, {"title": "Memory-Efficient Episodic Control Reinforcement Learning with Dynamic Online k-means", "summary": "Recently, neuro-inspired episodic control (EC) methods have been developed to overcome the data-inef"}, {"title": "Reinforcement Learning with Stepwise Fairness Constraints", "summary": "AI methods are used in societally important settings, ranging from credit to employment to housing, "}, {"title": "Sample-Efficient Reinforcement Learning with Maximum Entropy Mellowmax Episodic Control", "summary": "Deep networks have enabled reinforcement learning to scale to more complex and challenging domains, "}, {"title": "Biologically inspired architectures for sample-efficient deep reinforcement learning", "summary": "Deep reinforcement learning requires a heavy price in terms of sample efficiency and overparameteriz"}, {"title": "A Demonstration of Issues with Value-Based Multiobjective Reinforcement Learning Under Stochastic State Transitions", "summary": "We report a previously unidentified issue with model-free, value-based approaches to multiobjective "}, {"title": "Classifying Options for Deep Reinforcement Learning", "summary": "In this paper we combine one method for hierarchical reinforcement learning - the options framework "}, {"title": "Learning Multimodal Transition Dynamics for Model-Based Reinforcement Learning", "summary": "In this paper we study how to learn stochastic, multimodal transition dynamics in reinforcement lear"}, {"title": "Time Adaptive Reinforcement Learning", "summary": "Reinforcement learning (RL) allows to solve complex tasks such as Go often with a stronger performan"}, {"title": "An Optimistic Perspective on Offline Reinforcement Learning", "summary": "Off-policy reinforcement learning (RL) using a fixed offline dataset of logged interactions is an im"}, {"title": "Directed Policy Gradient for Safe Reinforcement Learning with Human Advice", "summary": "Many currently deployed Reinforcement Learning agents work in an environment shared with humans, be "}, {"title": "Comparing Deep Reinforcement Learning and Evolutionary Methods in Continuous Control", "summary": "Reinforcement Learning and the Evolutionary Strategy are two major approaches in addressing complica"}, {"title": "Deep Reinforcement Learning: An Overview", "summary": "We give an overview of recent exciting achievements of deep reinforcement learning (RL). We discuss "}, {"title": "Learning to Navigate in Mazes with Novel Layouts using Abstract Top-down Maps", "summary": "Learning navigation capabilities in different environments has long been one of the major challenges"}, {"title": "Multi-agent Deep Reinforcement Learning with Extremely Noisy Observations", "summary": "Multi-agent reinforcement learning systems aim to provide interacting agents with the ability to col"}, {"title": "FairDICE: Fairness-Driven Offline Multi-Objective Reinforcement Learning", "summary": "Multi-objective reinforcement learning (MORL) aims to optimize policies in the presence of conflicti"}, {"title": "Pre-trained Word Embeddings for Goal-conditional Transfer Learning in Reinforcement Learning", "summary": "Reinforcement learning (RL) algorithms typically start tabula rasa, without any prior knowledge of t"}, {"title": "Impoola: The Power of Average Pooling for Image-Based Deep Reinforcement Learning", "summary": "As image-based deep reinforcement learning tackles more challenging tasks, increasing model size has"}, {"title": "Rating-based Reinforcement Learning", "summary": "This paper develops a novel rating-based reinforcement learning approach that uses human ratings to "}, {"title": "Vanishing Bias Heuristic-guided Reinforcement Learning Algorithm", "summary": "Reinforcement Learning has achieved tremendous success in the many Atari games. In this paper we exp"}, {"title": "ChainerRL: A Deep Reinforcement Learning Library", "summary": "In this paper, we introduce ChainerRL, an open-source deep reinforcement learning (DRL) library buil"}]}}
{"timestamp": "2025-11-17T13:30:40.183928", "type": "collection", "data": {"collected_count": 0, "papers": []}}
