import joblib, shutil, os
import json, time
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from pathlib import Path

LOG_PATH = "logs/experiment_log.json"  # ë¡œê·¸ ê²½ë¡œ
MODEL_DIR = "models"  # ëª¨ë¸ ì €ì¥ í´ë”
LATEST_LINK = os.path.join(MODEL_DIR, "reward_latest.pkl")


def load_logs(path: str = LOG_PATH) -> pd.DataFrame:
    with open(path, "r") as f:
        data = json.load(f)
    return pd.DataFrame(data)


def preprocess(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()

    for col in ("paper_title", "idea", "paper_summary"):
        if col not in df.columns:
            df[col] = ""
        df[col] = df[col].fillna("").astype(str)

    df["text"] = (df["paper_title"] + " " + df["idea"] + " " +
                  df["paper_summary"]).str.strip()

    def _to_bin_local(x):
        if x is None:
            return np.nan
        s = str(x).strip().lower()
        if s in {"1", "true", "yes", "y"}:
            return 1
        if s in {"0", "false", "no", "n"}:
            return 0
        try:
            return 1 if float(s) > 0 else 0
        except Exception:
            return np.nan

    df["reward_bin"] = df.get("reward", np.nan).apply(_to_bin_local)
    df = df.dropna(subset=["text", "reward_bin"]).copy()
    df["reward_bin"] = df["reward_bin"].astype(int)
    return df[["text", "reward_bin"]]


def _save_versioned(model):
    os.makedirs(MODEL_DIR, exist_ok=True)
    ts = time.strftime("%Y%m%d-%H%M%S")
    versioned = os.path.join(MODEL_DIR, f"reward_cls_{ts}.pkl")
    joblib.dump(model, versioned)
    # latest ì‹¬ë§í¬/ë³µì‚¬
    try:
        if os.path.islink(LATEST_LINK) or os.path.exists(LATEST_LINK):
            os.unlink(LATEST_LINK)
        os.symlink(os.path.basename(versioned), LATEST_LINK)
    except OSError:
        joblib.dump(model, LATEST_LINK)
    print(f"ğŸ“¦ ëª¨ë¸ ì €ì¥: {versioned}")
    print(f"ğŸ”— ìµœì‹  ëª¨ë¸ ê°±ì‹ : {LATEST_LINK}")


MODELS_DIR = "models"
LATEST_LINK = os.path.join(MODELS_DIR, "reward_latest.pkl")


def _save_versioned(pipeline):
    os.makedirs(MODELS_DIR, exist_ok=True)
    ts = time.strftime("%Y%m%d_%H%M%S")
    versioned = os.path.join(MODELS_DIR, f"reward_cls_{ts}.pkl")

    # ë²„ì „ íŒŒì¼ ì €ì¥ (pipeline í•˜ë‚˜ë§Œ ì €ì¥)
    joblib.dump(pipeline, versioned)

    # ìµœì‹  ë§í¬/ë³µì‚¬ ê°±ì‹  (replitì—ì„œ symlink ì‹¤íŒ¨ ëŒ€ë¹„)
    try:
        if os.path.islink(LATEST_LINK) or os.path.exists(LATEST_LINK):
            os.remove(LATEST_LINK)
        os.symlink(os.path.basename(versioned), LATEST_LINK)
    except Exception:
        shutil.copyfile(versioned, LATEST_LINK)  # ë§í¬ ì‹¤íŒ¨ ì‹œ íŒŒì¼ ë³µì‚¬ë¡œ ëŒ€ì²´


ROOT = Path(__file__).resolve().parents[1]
MODELS_DIR = ROOT / "models"
LATEST = MODELS_DIR / "reward_latest.pkl"


def _coerce_to_pipeline(obj):
    if isinstance(obj, Pipeline):
        return obj
    if isinstance(obj, tuple) and len(obj) == 2:
        a, b = obj

        def is_vec(x):
            return hasattr(x, "fit") and hasattr(
                x, "transform") and not hasattr(x, "predict")

        def is_clf(x):
            return hasattr(x, "fit") and hasattr(x, "predict")

        if is_vec(a) and is_clf(b):
            return Pipeline([("vectorizer", a), ("clf", b)])
        if is_vec(b) and is_clf(a):
            return Pipeline([("vectorizer", b), ("clf", a)])
        clf = a if is_clf(a) else b
        return make_pipeline(TfidfVectorizer(), clf)
    if hasattr(obj, "fit") and hasattr(obj, "predict"):
        return make_pipeline(TfidfVectorizer(), obj)
    raise TypeError("Pipeline/íŠœí”Œ/ë¶„ë¥˜ê¸°ë§Œ í—ˆìš©")


def save_pipeline(pipeline_or_tuple, keep: int = 5):
    MODELS_DIR.mkdir(parents=True, exist_ok=True)
    pipeline = _coerce_to_pipeline(pipeline_or_tuple)
    ts = time.strftime("%Y%m%d_%H%M%S")
    versioned = MODELS_DIR / f"reward_cls_{ts}.pkl"
    joblib.dump(pipeline, versioned)
    try:
        if LATEST.exists() or LATEST.is_symlink():
            LATEST.unlink()
        os.symlink(versioned.name, LATEST)
    except Exception:
        shutil.copyfile(versioned, LATEST)
    # ë¡¤ë§ ì •ë¦¬
    cands = sorted(MODELS_DIR.glob("reward_cls_*.pkl"),
                   key=lambda p: p.stat().st_mtime,
                   reverse=True)
    for p in cands[keep:]:
        try:
            p.unlink()
        except:
            pass


def load_feedback_df(path="feedback.jsonl"):
    rows = []
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    o = json.loads(line)
                    rows.append({
                        "text":
                        o["text"],
                        "reward_bin":
                        int(o.get("label", o.get("prediction", 0)))
                    })
                except:
                    pass
    return pd.DataFrame(rows, columns=["text", "reward_bin"])


def train_model():
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.pipeline import make_pipeline
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.linear_model import LogisticRegression
    from sklearn.metrics import accuracy_score, f1_score

    # 0) ì›ë³¸ ë¡œê·¸ + í”¼ë“œë°± ë¡œë“œ
    df_logs = load_logs()  # ê¸°ì¡´ ë¡œê·¸ (text, label/reward_bin ë“±)
    fb = load_feedback_df()  # feedback.jsonl â†’ (text, reward_bin) í˜•íƒœ ê¶Œì¥

    # 1) ì „ì²˜ë¦¬ ì „ì— í•©ì¹˜ê¸° (ê°™ì€ ê·œì¹™ìœ¼ë¡œ í•œ ë²ˆë§Œ preprocess)
    if fb is not None and not fb.empty:
        # í˜¹ì‹œ feedbackì— 'label'ë¡œ ë“¤ì–´ì™”ë‹¤ë©´ ì´ë¦„ ë§ì¶°ì¤Œ
        if "reward_bin" not in fb.columns and "label" in fb.columns:
            fb = fb.rename(columns={"label": "reward_bin"})
        fb = fb[["text", "reward_bin"]]
        df = pd.concat([df_logs, fb], ignore_index=True)
    else:
        df = df_logs

    # 2) ê³µí†µ ì „ì²˜ë¦¬
    df = preprocess(df)

    # 3) ì •í•©ì„± ì²´í¬
    if df is None or df.empty:
        print("â— í•™ìŠµ ë¶ˆê°€: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. /seedÂ·/ingestÂ·/feedbackìœ¼ë¡œ ë°ì´í„°ë¥¼ ìŒ“ì•„ì£¼ì„¸ìš”.")
        return
    if "text" not in df.columns or "reward_bin" not in df.columns:
        print("â— í•™ìŠµ ë¶ˆê°€: í•„ìš”í•œ ì»¬ëŸ¼(text, reward_bin)ì´ ì—†ìŠµë‹ˆë‹¤. preprocess()ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    df = df.dropna(subset=["text", "reward_bin"])
    df["reward_bin"] = df["reward_bin"].astype(int)

    # í´ë˜ìŠ¤ ìˆ˜/ë¶„í¬ ì ê²€ (stratify ì•ˆì •í™”)
    if df["reward_bin"].nunique() < 2:
        print("â— í•™ìŠµ ë¶ˆê°€: ë¼ë²¨ì´ í•œ ê°€ì§€ë¿ì…ë‹ˆë‹¤. 0/1 ë‘˜ ë‹¤ ë“¤ì–´ì˜¤ê²Œ /ingestÂ·/feedbackì„ ì¶”ê°€í•˜ì„¸ìš”.")
        return
    # ê° í´ë˜ìŠ¤ ìµœì†Œ 2ê°œ ì´ìƒ ê¶Œì¥ (stratifyì— í•„ìš”)
    if df["reward_bin"].value_counts().min() < 2:
        print("â— í•™ìŠµ ë¶ˆê°€: ê° í´ë˜ìŠ¤ ìµœì†Œ 2ê°œ ì´ìƒ í•„ìš”. ìƒ˜í”Œì„ ë” ë„£ì–´ì£¼ì„¸ìš”.")
        return

    # 4) ë°ì´í„° ë¶„ë¦¬
    X_train, X_test, y_train, y_test = train_test_split(
        df["text"],
        df["reward_bin"],
        test_size=0.2,
        random_state=42,
        stratify=df["reward_bin"])

    # 5) íŒŒì´í”„ë¼ì¸ í•™ìŠµ
    model = make_pipeline(
        TfidfVectorizer(),
        LogisticRegression(max_iter=1000, class_weight="balanced"))
    model.fit(X_train, y_train)

    # 6) í‰ê°€(ë¡œê·¸ìš©)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    print(f"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (ì •í™•ë„: {acc:.2f}, F1: {f1:.2f})")

    # 7) ì €ì¥ (í•­ìƒ Pipelineë¡œ ì €ì¥)
    save_pipeline(model)


def train_model_from_logs():
    try:
        train_model()
    except Exception as e:
        print(f"ğŸ”¥ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    train_model()
