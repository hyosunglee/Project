ì•„ì£¼ ì˜ ëë‹¤ ğŸ˜
ê²½ë¡œ OK, ê·¸ë¦¬ê³  ì´ì œ ì§„ì§œ ëª¨ë¸ í•™ìŠµí•˜ê³  ì˜ˆì¸¡ê¹Œì§€ ìë™í™”í•œë‹¤.

â¸»

ğŸ” Step 1: result ê°’ ì•ˆì— ì •í™•íˆ ë­ê°€ ë“¤ì–´ìˆëŠ”ì§€ í™•ì¸

âœ… í™•ì¸ ë°©ë²•

logs/experiment_logs.json íŒŒì¼ì—ì„œ "result" í•­ëª©ë§Œ ì‹¹ ëª¨ì•„ì„œ í™•ì¸í•˜ë©´ ë¼.
ì½”ë“œë¡œ í•˜ë©´ ì•„ì£¼ ê°„ë‹¨í•´:

import json

with open("logs/experiment_logs.json", "r") as f:
Â Â Â Â logs = json.load(f)

results = [log.get("result", "") for log in logs]

for i, r in enumerate(results):
Â Â Â Â print(f"{i+1}. {r}")

ì´ê±¸ë¡œ ì•„ë˜ ê°™ì€ ì¶œë ¥ì´ ë‚˜ì˜¬ ê±°ì•¼:

1. Experiment with accuracy 0.81
2. Reward: 0.9
3. Success rate = 78%
4. Experiment with accuracy 0.73


â¸»

ğŸ§  ì´ë ‡ê²Œ ì²˜ë¦¬í•˜ë©´ ì¢‹ìŒ
	1.	accuracy ìˆëŠ” ê±´ â†’ accuracy ì˜ˆì¸¡ìš© í•™ìŠµ
	2.	reward, success, etc. ìˆëŠ” ê±´ â†’ ì¶”í›„ í™•ì¥ (ë©€í‹°íƒ€ê¹ƒ or ì¡°ê±´ë³„)

ìš°ì„ ì€ accuracyë§Œ ì¶”ì¶œí•´ì„œ ì„ í˜•íšŒê·€ ëª¨ë¸ ë§Œë“¤ì–´ë³´ì.

â¸»

âœ… ìµœì¢… ëª¨ë¸ í•™ìŠµ ì½”ë“œ

ğŸ“ utils/model_trainer.py íŒŒì¼ì— ì•„ë˜ ì „ì²´ ì½”ë“œ ë³µë¶™í•´ë„ ë¼:

import json
import re
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error


def extract_accuracy(result_str):
Â Â Â Â match = re.search(r"accuracy\s*([0-9.]+)", result_str, re.IGNORECASE)
Â Â Â Â if match:
Â Â Â Â Â Â Â Â return float(match.group(1))
Â Â Â Â return None


def train_model_from_logs():
Â Â Â Â with open("logs/experiment_logs.json", "r") as f:
Â Â Â Â Â Â Â Â logs = json.load(f)

Â Â Â Â X_texts = []
Â Â Â Â y = []

Â Â Â Â for log in logs:
Â Â Â Â Â Â Â Â acc = extract_accuracy(log.get("result", ""))
Â Â Â Â Â Â Â Â if acc is None:
Â Â Â Â Â Â Â Â Â Â Â Â continue

Â Â Â Â Â Â Â Â input_text = f"{log.get('summary', '')} {log.get('idea', '')} {log.get('code', '')}"
Â Â Â Â Â Â Â Â X_texts.append(input_text)
Â Â Â Â Â Â Â Â y.append(acc)

Â Â Â Â if len(X_texts) < 5:
Â Â Â Â Â Â Â Â print("â— í•™ìŠµ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ìµœì†Œ 5ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.")
Â Â Â Â Â Â Â Â return

Â Â Â Â vectorizer = TfidfVectorizer(max_features=1000)
Â Â Â Â X = vectorizer.fit_transform(X_texts)

Â Â Â Â X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

Â Â Â Â model = LinearRegression()
Â Â Â Â model.fit(X_train, y_train)

Â Â Â Â pred = model.predict(X_test)
Â Â Â Â mse = mean_squared_error(y_test, pred)
Â Â Â Â print(f"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ. í…ŒìŠ¤íŠ¸ MSE: {mse:.4f}")


â¸»

ğŸš€ í•™ìŠµ ì‹¤í–‰
	1.	/loop ëª‡ ë²ˆ í˜¸ì¶œí•´ì„œ ë°ì´í„° ìŒ“ê³ 
	2.	ì•„ë˜ë¡œ í•™ìŠµ íŠ¸ë¦¬ê±°:

curl -X POST http://localhost:3000/train

	3.	í„°ë¯¸ë„ì— ê²°ê³¼ í™•ì¸:

âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ. í…ŒìŠ¤íŠ¸ MSE: 0.0148


â¸»

ğŸ”® ë‹¤ìŒ ìŠ¤í…
	â€¢	ì˜ˆì¸¡ ëª¨ë¸ ì €ì¥ (joblib) â†’ ì‹¤í—˜ ì „ì— ë¯¸ë¦¬ â€œì¢‹ì„ ê²ƒ ê°™ì€ ë…¼ë¬¸â€ ì˜ˆì¸¡
	â€¢	reward, success rate, loss ë“±ë„ ì˜ˆì¸¡ (ë©€í‹°íƒ€ê¹ƒ)
	â€¢	ì‹œê°í™”: ì–´ë–¤ ë‹¨ì–´ê°€ ë†’ì€ ì„±ëŠ¥ì— ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ì§€ (SHAP, permutation importance)
	â€¢	ì„±ëŠ¥ ë†’ì€ ë…¼ë¬¸ ì•„ì´ë””ì–´ë§Œ ìë™ ì„ íƒ ì‹¤í—˜ ğŸ§ âš™ï¸

â¸»

ì´ì œ ëª¨ë¸ì€ ì‚´ì•„ìˆë‹¤.
ì‹¤í—˜ ì „ ì˜ˆì¸¡ë„ ê°€ëŠ¥í•´ì§€ê³ , ì—°êµ¬ ìë™í™”ì˜ í•µì‹¬ë¶€ë¡œ ë“¤ì–´ì™”ì–´.

ğŸ“¢ ì§€ê¸ˆë¶€í„°ëŠ” ì§„ì§œ â€œì„±ëŠ¥ì„ ì˜ˆì¸¡í•´ ë¨¼ì € íŒë‹¨í•˜ê³ , ì‹¤í—˜ì€ ë‚˜ì¤‘â€ì¸ ì‹œëŒ€ì•¼.
ì›í•˜ë©´ ë°”ë¡œ ì˜ˆì¸¡ APIê¹Œì§€ ë¶™ì—¬ì¤„ê²Œ. ê³„ì† ê°€ë³¼ê¹Œ? ğŸ˜