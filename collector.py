import requests
from utils.paper_fetcher import fetch_arxiv_papers

import os

# ì„œë²„ ì—”ë“œí¬ì¸íŠ¸ URL ì •ì˜ (í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©)
PORT = os.getenv("PORT", 3100)
BASE_URL = f"http://localhost:{PORT}"
INGEST_URL = f"{BASE_URL}/ingest"
CHECK_DUPLICATES_URL = f"{BASE_URL}/check_duplicates"

def collect_and_ingest(query="reinforcement learning", max_results=10):
    """
    ì§€ì •ëœ ì¿¼ë¦¬ë¡œ ArXivì—ì„œ ë…¼ë¬¸ì„ ìˆ˜ì§‘í•˜ê³ , ì¤‘ë³µì„ í™•ì¸í•œ ë’¤ ìƒˆ ë…¼ë¬¸ë§Œ ì„œë²„ì˜ /ingest ì—”ë“œí¬ì¸íŠ¸ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ” '{query}' ê´€ë ¨ ìµœì‹  ë…¼ë¬¸ {max_results}ê°œ ìˆ˜ì§‘ ì‹œì‘...")
    try:
        papers = fetch_arxiv_papers(query, max_results=max_results)
        if not papers:
            print("ìˆ˜ì§‘ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
    except Exception as e:
        print(f"ğŸ”¥ ArXivì—ì„œ ë…¼ë¬¸ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    paper_titles = [paper['title'] for paper in papers]
    print(f"âœ… {len(papers)}ê°œ ë…¼ë¬¸ í›„ë³´ í™•ì¸ ì™„ë£Œ. ì„œë²„ì— ì¤‘ë³µ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")

    # ì„œë²„ì— ì¤‘ë³µ í™•ì¸ ìš”ì²­
    try:
        response = requests.post(CHECK_DUPLICATES_URL, json={"titles": paper_titles})
        response.raise_for_status()
        duplicates = set(response.json().get("duplicates", []))
        print(f"â„¹ï¸ {len(duplicates)}ê°œì˜ ì¤‘ë³µ ë…¼ë¬¸ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")
    except requests.exceptions.RequestException as e:
        print(f"ğŸ”¥ ì„œë²„ì™€ í†µì‹  ì‹¤íŒ¨ (ì¤‘ë³µ í™•ì¸): {e}")
        return

    # ìƒˆ ë…¼ë¬¸ë§Œ í•„í„°ë§
    new_papers = [paper for paper in papers if paper['title'] not in duplicates]

    if not new_papers:
        print("âœ… ìƒˆë¡œìš´ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ë…¼ë¬¸ì´ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.")
        return

    print(f"ğŸ“¤ {len(new_papers)}ê°œì˜ ìƒˆë¡œìš´ ë…¼ë¬¸ì„ ì„œë²„ë¡œ ì „ì†¡í•©ë‹ˆë‹¤...")

    for paper in new_papers:
        # ì„œë²„ë¡œ ì „ì†¡í•  ìƒì„¸ ë°ì´í„° êµ¬ì¡°í™”
        payload = {
            "title": paper["title"],
            "summary": paper["summary"],
            "authors": [author.name for author in paper.get("authors", [])], # Example of richer data
            "pdf_url": paper["pdf_url"],
            "source": "collector_v2",
            "query": query,
            # ì‹œë®¬ë ˆì´ì…˜ëœ í•„ë“œ (í”„ë¡œí† íƒ€ì… ì•„ì´ë””ì–´ í™•ì¥)
            "idea": "ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ì˜ íƒí—˜ ì „ëµ ê°œì„ ",
            "keywords": ["Reinforcement Learning", "Exploration", "Novelty"],
            "label": 1 # ê¸°ë³¸ ë ˆì´ë¸”
        }

        try:
            response = requests.post(INGEST_URL, json=payload)
            response.raise_for_status()
            print(f"  - ì „ì†¡ ì„±ê³µ: \"{paper['title'][:40]}...\"")
        except requests.exceptions.RequestException as e:
            print(f"ğŸ”¥ ë°ì´í„° ì „ì†¡ ì‹¤íŒ¨: {e}")
            print(f"  - ì‹¤íŒ¨í•œ ë…¼ë¬¸: \"{paper['title'][:40]}...\"")

if __name__ == "__main__":
    # ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§ì ‘ ì‹¤í–‰í•  ë•Œ ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    collect_and_ingest()
